from __future__ import annotations
from agent.utils import get_latest_user_message
from agent.rag import rag_search, ensure_index_built
from agent.llm import get_llm
from .state import ErrorDetectionState
from typing import Dict, Any
from langgraph.graph import END
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from agent.config import Config


llm = get_llm()


def chat_node(state: ErrorDetectionState) -> Dict[str, Any]:
    """Handle conversational API error help."""
    messages = state.get("messages", [])

    # If no messages yet, show the welcome message
    if not messages:
        return {
            "messages": [
                AIMessage(content=(
                    "# ðŸ” API Error Hilfe\n\n"
                    "Hallo! Ich helfe bei Problemen mit der AEB TCM Screening API.\n\n"
                    "Sie kÃ¶nnen mir einfach beschreiben was passiert ist - zum Beispiel:\n"
                    "â€¢ \"Ich bekomme einen 400 Fehler\"\n"
                    "â€¢ \"Mein Request funktioniert nicht\"\n"
                    "â€¢ \"Was bedeutet dieser Error Code?\"\n\n"
                    "Was ist das Problem?"
                ))
            ]
        }

    # Get the user's question
    user_input = get_latest_user_message(messages)

    if not user_input or not user_input.strip():
        return {}

    ensure_index_built(Config.KNOWLEDGE_BASE_DIR.as_posix(),
                       Config.KNOWLEDGE_BASE_VECTOR_STORE)

    # TODO: Get error codes documentation via RAG search when available
    try:
        relevant_docs = rag_search(f"API error help: {user_input}", k=3)
    except Exception:
        relevant_docs = []

    # Create a conversational system prompt
    sys = SystemMessage(content=(
        "Du bist ein hilfsbereiter API-Support fÃ¼r die AEB TCM Screening API. "
        "Beantworte Fragen zu API-Fehlern kurz und prÃ¤zise auf Deutsch. "
        "Sei freundlich und gesprÃ¤chig. Wenn der Benutzer Code oder Errors zeigt, analysiere sie. "
        "Nutze den gesamten GesprÃ¤chsverlauf um den Kontext zu verstehen. "
        "Wenn keine spezifischen Docs verfÃ¼gbar sind, nutze dein Wissen Ã¼ber hÃ¤ufige API-Probleme.\n\n"

        "HÃ„UFIGE API-FEHLER:\n"
        "â€¢ 400 Bad Request: Syntax-/Validierungsfehler\n"
        "â€¢ 401 Unauthorized: Authentifizierung fehlt\n"
        "â€¢ 403 Forbidden: Keine Berechtigung\n"
        "â€¢ 404 Not Found: Endpoint falsch\n"
        "â€¢ 500 Server Error: Backend-Problem\n\n"

        "HÃ„UFIGE TYPOS:\n"
        "â€¢ 'addresse' statt 'addresses'\n"
        "â€¢ 'clientId' statt 'clientIdentCode'\n"
        "â€¢ 'suppressLog' statt 'suppressLogging'\n\n"

        "Antworte kurz und hilfsbereit. Frage nach, wenn du mehr Details brauchst.\n"

        "VerfÃ¼gbare DokumentationsauszÃ¼ge:\n" +
        ("\n".join(relevant_docs)
         if relevant_docs else "Keine relevanten Dokumente gefunden.")
    ))

    human = HumanMessage(content=user_input)
    try:
        response = llm.invoke([sys, *messages, human])
    except Exception as e:
        response = AIMessage(
            content=f"Entschuldigung, da ist ein Fehler aufgetreten: {str(e)}")

    return {
        "messages": [response]
    }


def route_chat(state: ErrorDetectionState) -> str:
    """Simple routing - always stay in chat mode."""
    return END
